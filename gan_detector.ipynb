{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26d6f5a",
   "metadata": {},
   "source": [
    "# 小样本遥感异常检测 - 条件GAN方案 (Task 2)\n",
    "\n",
    "- 任务要求：利用生成对抗网络 (GAN) 对原始数据进行扩增，并在增强后的数据上完成油气渗漏检测。\n",
    "- 本 notebook 给出数据准备、cGAN 模型（UNet Generator + PatchGAN Discriminator）、训练与推理的完整流程。\n",
    "- 默认在 `DATASET2` 目录运行，训练完成后输出 120 个测试结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4dcef",
   "metadata": {},
   "source": [
    "## 1. 环境配置与全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "DATA_ROOT = Path('d:/BaiduNetdiskDownload/dataset_work_final')\n",
    "TRAIN_IMG_DIR = DATA_ROOT / 'images' / 'train'\n",
    "TEST_IMG_DIR = DATA_ROOT / 'images' / 'test'\n",
    "LABEL_DIR = DATA_ROOT / 'labels' / 'train'\n",
    "CHECKPOINT_DIR = DATA_ROOT / 'artifacts_gan'\n",
    "RESULT_DIR = DATA_ROOT / 'results_cgan'\n",
    "\n",
    "for path in [CHECKPOINT_DIR, RESULT_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLASS_NAMES = ['Oil_accumulation', 'Oil_seepage', 'Standing_water']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "IMAGE_SIZE = (288, 512)\n",
    "SEED = 42\n",
    "FAST_DEBUG = False  # set True for smoke test\n",
    "FAST_TRAIN_LIMIT = 256\n",
    "FAST_VAL_LIMIT = 64\n",
    "VAL_FRACTION = 0.1\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 2e-4\n",
    "LAMBDA_L1 = 50.0\n",
    "LAMBDA_DICE = 1.0\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_WORKERS = 0 if os.name == 'nt' else 4\n",
    "PIN_MEMORY = DEVICE == 'cuda'\n",
    "\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything()\n",
    "print(f'device: {DEVICE}')\n",
    "print(f'train images: {len(list(TRAIN_IMG_DIR.glob(\"*.jpg\")))}, test images: {len(list(TEST_IMG_DIR.glob(\"*.jpg\")))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9af303",
   "metadata": {},
   "source": [
    "## 2. 数据加载与可视化辅助"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_boxes(label_path: Path):\n",
    "    boxes = []\n",
    "    if not label_path.exists():\n",
    "        return boxes\n",
    "    with label_path.open() as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls, cx, cy, w, h = map(float, parts)\n",
    "            cls = int(cls)\n",
    "            if cls >= NUM_CLASSES:\n",
    "                continue\n",
    "            boxes.append((cls, cx, cy, w, h))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def boxes_to_mask(boxes, out_h, out_w):\n",
    "    mask = np.zeros((out_h, out_w, NUM_CLASSES), dtype=np.float32)\n",
    "    for cls, cx, cy, bw, bh in boxes:\n",
    "        x1 = max(0, int((cx - bw / 2) * out_w))\n",
    "        x2 = min(out_w, int((cx + bw / 2) * out_w))\n",
    "        y1 = max(0, int((cy - bh / 2) * out_h))\n",
    "        y2 = min(out_h, int((cy + bh / 2) * out_h))\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "        mask[y1:y2, x1:x2, cls] = 1.0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_augmentations(image, mask):\n",
    "    if random.random() < 0.5:\n",
    "        image = image[:, ::-1].copy()\n",
    "        mask = mask[:, ::-1].copy()\n",
    "    if random.random() < 0.3:\n",
    "        alpha = 1.0 + 0.4 * (random.random() * 2 - 1)\n",
    "        beta = 20.0 * (random.random() * 2 - 1)\n",
    "        image = np.clip(image * alpha + beta, 0, 255)\n",
    "    if random.random() < 0.2:\n",
    "        noise = np.random.normal(0, 10, size=image.shape)\n",
    "        image = np.clip(image + noise, 0, 255)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def mask_overlay(image_tensor, mask_tensor):\n",
    "    image = image_tensor.numpy().transpose(1, 2, 0)\n",
    "    image = np.clip(image * 255.0, 0, 255).astype(np.uint8)\n",
    "    mask = mask_tensor.numpy().transpose(1, 2, 0)\n",
    "    colors = np.array([(255,0,0), (0,255,0), (0,0,255)])\n",
    "    overlay = image.copy().astype(np.float32)\n",
    "    for ch in range(min(mask.shape[-1], len(colors))):\n",
    "        cls_mask = mask[..., ch] > 0.5\n",
    "        overlay[cls_mask] = 0.6 * overlay[cls_mask] + 0.4 * colors[ch]\n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "\n",
    "class LeakDataset(Dataset):\n",
    "    def __init__(self, image_ids, image_dir, label_dir, augment=False):\n",
    "        self.image_ids = image_ids\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        img_path = self.image_dir / f'{image_id}.jpg'\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE[1], IMAGE_SIZE[0]), interpolation=cv2.INTER_LINEAR)\n",
    "        boxes = load_yolo_boxes(self.label_dir / f'{image_id}.txt')\n",
    "        mask = boxes_to_mask(boxes, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "        if self.augment:\n",
    "            image, mask = apply_augmentations(image, mask)\n",
    "        image = torch.from_numpy(image.transpose(2,0,1)).float() / 255.0\n",
    "        mask = torch.from_numpy(mask.transpose(2,0,1)).float()\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "class LeakInferenceDataset(Dataset):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = sorted(image_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        image = cv2.imread(str(path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        orig_h, orig_w = image.shape[:2]\n",
    "        image_resized = cv2.resize(image, (IMAGE_SIZE[1], IMAGE_SIZE[0]), interpolation=cv2.INTER_LINEAR)\n",
    "        tensor = torch.from_numpy(image_resized.transpose(2,0,1)).float() / 255.0\n",
    "        return tensor, path.stem, (orig_h, orig_w)\n",
    "\n",
    "\n",
    "all_ids = sorted([p.stem for p in TRAIN_IMG_DIR.glob('*.jpg')])\n",
    "random.Random(SEED).shuffle(all_ids)\n",
    "val_count = max(1, int(len(all_ids) * VAL_FRACTION))\n",
    "val_ids = sorted(all_ids[:val_count])\n",
    "train_ids = sorted(all_ids[val_count:])\n",
    "if FAST_DEBUG:\n",
    "    train_ids = train_ids[:FAST_TRAIN_LIMIT]\n",
    "    val_ids = val_ids[:FAST_VAL_LIMIT]\n",
    "print(f'train samples: {len(train_ids)}, val samples: {len(val_ids)}')\n",
    "with (CHECKPOINT_DIR / 'split_gan.json').open('w', encoding='utf-8') as f:\n",
    "    json.dump({'train_ids': train_ids, 'val_ids': val_ids}, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_ds = LeakDataset(train_ids[:4], TRAIN_IMG_DIR, LABEL_DIR)\n",
    "fig, axes = plt.subplots(1, len(preview_ds), figsize=(16,4))\n",
    "for ax, sample in zip(axes, preview_ds):\n",
    "    img, mask = sample\n",
    "    overlay = mask_overlay(img, mask)\n",
    "    ax.imshow(overlay)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Train samples with mask overlay (GAN pipeline)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42623b58",
   "metadata": {},
   "source": [
    "## 3. 条件GAN模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23987565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_norm=True):\n",
    "        super().__init__()\n",
    "        layers = [nn.Conv2d(in_ch, out_ch, 4, stride=2, padding=1, bias=not use_norm)]\n",
    "        if use_norm:\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.seq = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "\n",
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, dropout=False):\n",
    "        super().__init__()\n",
    "        layers = [nn.ConvTranspose2d(in_ch, out_ch, 4, stride=2, padding=1, bias=False),\n",
    "                  nn.BatchNorm2d(out_ch),\n",
    "                  nn.ReLU(inplace=True)]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "        self.seq = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=NUM_CLASSES, base_ch=64):\n",
    "        super().__init__()\n",
    "        self.down1 = ConvBlock(in_ch, base_ch, use_norm=False)\n",
    "        self.down2 = ConvBlock(base_ch, base_ch*2)\n",
    "        self.down3 = ConvBlock(base_ch*2, base_ch*4)\n",
    "        self.down4 = ConvBlock(base_ch*4, base_ch*8)\n",
    "        self.down5 = ConvBlock(base_ch*8, base_ch*8)\n",
    "        self.down6 = ConvBlock(base_ch*8, base_ch*8)\n",
    "        self.down7 = ConvBlock(base_ch*8, base_ch*8)\n",
    "        self.bottom = ConvBlock(base_ch*8, base_ch*8)\n",
    "        self.up1 = DeconvBlock(base_ch*8, base_ch*8, dropout=True)\n",
    "        self.up2 = DeconvBlock(base_ch*16, base_ch*8, dropout=True)\n",
    "        self.up3 = DeconvBlock(base_ch*16, base_ch*8, dropout=True)\n",
    "        self.up4 = DeconvBlock(base_ch*16, base_ch*8)\n",
    "        self.up5 = DeconvBlock(base_ch*16, base_ch*4)\n",
    "        self.up6 = DeconvBlock(base_ch*8, base_ch*2)\n",
    "        self.up7 = DeconvBlock(base_ch*4, base_ch)\n",
    "        self.final = nn.ConvTranspose2d(base_ch*2, out_ch, 4, stride=2, padding=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def match_size(x, ref):\n",
    "        if x.shape[2:] != ref.shape[2:]:\n",
    "            x = F.interpolate(x, size=ref.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        bott = self.bottom(d7)\n",
    "        u1 = self.up1(bott)\n",
    "        u1 = torch.cat([self.match_size(u1, d7), d7], dim=1)\n",
    "        u2 = self.up2(u1)\n",
    "        u2 = torch.cat([self.match_size(u2, d6), d6], dim=1)\n",
    "        u3 = self.up3(u2)\n",
    "        u3 = torch.cat([self.match_size(u3, d5), d5], dim=1)\n",
    "        u4 = self.up4(u3)\n",
    "        u4 = torch.cat([self.match_size(u4, d4), d4], dim=1)\n",
    "        u5 = self.up5(u4)\n",
    "        u5 = torch.cat([self.match_size(u5, d3), d3], dim=1)\n",
    "        u6 = self.up6(u5)\n",
    "        u6 = torch.cat([self.match_size(u6, d2), d2], dim=1)\n",
    "        u7 = self.up7(u6)\n",
    "        u7 = torch.cat([self.match_size(u7, d1), d1], dim=1)\n",
    "        out = self.final(u7)\n",
    "        if out.shape[2:] != x.shape[2:]:\n",
    "            out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, in_ch=3 + NUM_CLASSES, base_ch=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            ConvBlock(in_ch, base_ch, use_norm=False),\n",
    "            ConvBlock(base_ch, base_ch*2),\n",
    "            ConvBlock(base_ch*2, base_ch*4),\n",
    "            nn.Conv2d(base_ch*4, 1, 4, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        inp = torch.cat([x, y], dim=1)\n",
    "        return self.model(inp)\n",
    "\n",
    "\n",
    "generator = UNetGenerator().to(DEVICE)\n",
    "discriminator = PatchDiscriminator().to(DEVICE)\n",
    "print('Generator params:', sum(p.numel() for p in generator.parameters())/1e6, 'M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7bf209",
   "metadata": {},
   "source": [
    "## 4. 损失函数与训练辅助"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bfe17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def dice_loss(preds, targets, eps=1e-6):\n",
    "    probs = torch.sigmoid(preds)\n",
    "    dims = (0,2,3)\n",
    "    intersection = (probs * targets).sum(dim=dims)\n",
    "    union = probs.sum(dim=dims) + targets.sum(dim=dims)\n",
    "    dice = (2*intersection + eps)/(union + eps)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "\n",
    "def generator_loss(gen_out, real_imgs, real_masks):\n",
    "    fake_disc = discriminator(real_imgs, gen_out)\n",
    "    valid = torch.ones_like(fake_disc)\n",
    "    adv = adv_criterion(fake_disc, valid)\n",
    "    l1 = F.l1_loss(gen_out, real_masks)\n",
    "    dloss = dice_loss(gen_out, real_masks)\n",
    "    return adv + LAMBDA_L1 * l1 + LAMBDA_DICE * dloss, {'adv': adv.item(), 'l1': l1.item(), 'dice': dloss.item()}\n",
    "\n",
    "\n",
    "def discriminator_loss(real_imgs, real_masks, fake_masks):\n",
    "    valid = torch.ones_like(discriminator(real_imgs, real_masks))\n",
    "    fake = torch.zeros_like(valid)\n",
    "    real_pred = discriminator(real_imgs, real_masks)\n",
    "    fake_pred = discriminator(real_imgs, fake_masks.detach())\n",
    "    loss_real = adv_criterion(real_pred, valid)\n",
    "    loss_fake = adv_criterion(fake_pred, fake)\n",
    "    return 0.5 * (loss_real + loss_fake)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04706b73",
   "metadata": {},
   "source": [
    "## 5. 训练与验证循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LeakDataset(train_ids, TRAIN_IMG_DIR, LABEL_DIR, augment=True)\n",
    "val_dataset = LeakDataset(val_ids, TRAIN_IMG_DIR, LABEL_DIR, augment=False)\n",
    "loader_kwargs = dict(batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, **loader_kwargs)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, **loader_kwargs)\n",
    "print(f'train batches: {len(train_loader)}, val batches: {len(val_loader)}')\n",
    "\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    generator.train(); discriminator.train()\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{EPOCHS}')\n",
    "    total_g, total_d = 0.0, 0.0\n",
    "    for images, masks in pbar:\n",
    "        images = images.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        fake_masks = generator(images)\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        d_loss = discriminator_loss(images, masks, fake_masks)\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        optimizer_g.zero_grad()\n",
    "        g_loss, comps = generator_loss(fake_masks, images, masks)\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        total_g += g_loss.item()\n",
    "        total_d += d_loss.item()\n",
    "        pbar.set_postfix({'g': g_loss.item(), 'd': d_loss.item()})\n",
    "\n",
    "    generator.eval()\n",
    "    val_l1 = 0.0\n",
    "    val_dice = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            preds = generator(images)\n",
    "            val_l1 += F.l1_loss(preds, masks).item()\n",
    "            val_dice += (1 - dice_loss(preds, masks)).item()\n",
    "    val_l1 /= max(1, len(val_loader))\n",
    "    val_dice /= max(1, len(val_loader))\n",
    "    rec = {'epoch': epoch, 'g_loss': total_g / len(train_loader), 'd_loss': total_d / len(train_loader),\n",
    "           'val_l1': val_l1, 'val_dice': val_dice}\n",
    "    history.append(rec)\n",
    "    print(rec)\n",
    "    torch.save({'generator': generator.state_dict(), 'discriminator': discriminator.state_dict(), 'epoch': epoch}, CHECKPOINT_DIR / 'cgan_detector.pt')\n",
    "\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d23003",
   "metadata": {},
   "source": [
    "## 6. 可视化训练曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac20b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if history:\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "    g_losses = [h['g_loss'] for h in history]\n",
    "    d_losses = [h['d_loss'] for h in history]\n",
    "    val_l1 = [h['val_l1'] for h in history]\n",
    "    val_dice = [h['val_dice'] for h in history]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "    axes[0].plot(epochs, g_losses, label='generator')\n",
    "    axes[0].plot(epochs, d_losses, label='discriminator')\n",
    "    axes[0].set_title('Adversarial losses')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(epochs, val_l1, label='val L1')\n",
    "    axes[1].plot(epochs, val_dice, label='val Dice')\n",
    "    axes[1].legend(); axes[1].set_title('Validation metrics')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f6446",
   "metadata": {},
   "source": [
    "## 7. 推理与结果导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probmap_to_boxes(prob_map, min_area_ratio=1e-4, threshold=0.45, min_score=0.3, nms_thresh=0.4):\n",
    "    boxes = []\n",
    "    channels, h, w = prob_map.shape\n",
    "    for cls_idx in range(channels):\n",
    "        cls_map = prob_map[cls_idx]\n",
    "        heat = cv2.GaussianBlur(cls_map, (5,5), 0)\n",
    "        mask = (heat >= threshold).astype(np.uint8)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            x, y, bw, bh = cv2.boundingRect(cnt)\n",
    "            if bw * bh < min_area_ratio * h * w:\n",
    "                continue\n",
    "            score = float(heat[y:y+bh, x:x+bw].mean())\n",
    "            if score < min_score:\n",
    "                continue\n",
    "            boxes.append([cls_idx, score, x, y, bw, bh])\n",
    "    boxes = sorted(boxes, key=lambda x: x[1], reverse=True)\n",
    "    keep = []\n",
    "    while boxes:\n",
    "        current = boxes.pop(0)\n",
    "        keep.append(current)\n",
    "        boxes = [b for b in boxes if box_iou(current, b) < nms_thresh]\n",
    "    normalized = []\n",
    "    for cls_idx, score, x, y, bw, bh in keep:\n",
    "        cx = (x + bw / 2) / w\n",
    "        cy = (y + bh / 2) / h\n",
    "        nw = bw / w\n",
    "        nh = bh / h\n",
    "        normalized.append((cls_idx, score, cx, cy, nw, nh))\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def box_iou(box_a, box_b):\n",
    "    xa1, ya1 = box_a[2], box_a[3]\n",
    "    xa2, ya2 = xa1 + box_a[4], box_a[5]\n",
    "    xb1, yb1 = box_b[2], box_b[3]\n",
    "    xb2, yb2 = xb1 + box_b[4], box_b[5]\n",
    "    inter_x1, inter_y1 = max(xa1, xb1), max(ya1, yb1)\n",
    "    inter_x2, inter_y2 = min(xa2, xb2), min(ya2, yb2)\n",
    "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "    area_a = box_a[4] * box_a[5]\n",
    "    area_b = box_b[4] * box_b[5]\n",
    "    return inter_area / (area_a + area_b - inter_area + 1e-6)\n",
    "\n",
    "\n",
    "def write_prediction(image_id, boxes):\n",
    "    path = RESULT_DIR / f'{image_id}.txt'\n",
    "    with path.open('w') as f:\n",
    "        for cls, score, cx, cy, w, h in boxes:\n",
    "            f.write(f'{cls} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\n",
    "')\n",
    "    return path\n",
    "\n",
    "\n",
    "checkpoint = CHECKPOINT_DIR / 'cgan_detector.pt'\n",
    "assert checkpoint.exists(), '请先完成训练 checkpoint'\n",
    "state = torch.load(checkpoint, map_location=DEVICE)\n",
    "generator.load_state_dict(state['generator'])\n",
    "generator.eval()\n",
    "print('Loaded checkpoint from', checkpoint)\n",
    "\n",
    "for old in RESULT_DIR.glob('*.txt'):\n",
    "    old.unlink()\n",
    "\n",
    "test_paths = sorted(TEST_IMG_DIR.glob('*.jpg'))\n",
    "test_dataset = LeakInferenceDataset(test_paths)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, total=len(test_loader)):\n",
    "        images, image_ids, original_sizes = batch\n",
    "        images = images.to(DEVICE)\n",
    "        logits = generator(images)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        for prob, image_id, (orig_h, orig_w) in zip(probs, image_ids, original_sizes):\n",
    "            resized = np.stack([\n",
    "                cv2.resize(prob[c], (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)\n",
    "                for c in range(prob.shape[0])\n",
    "            ])\n",
    "            boxes = probmap_to_boxes(resized)\n",
    "            write_prediction(image_id, boxes)\n",
    "\n",
    "print('result files:', len(list(RESULT_DIR.glob('*.txt'))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74f2998",
   "metadata": {},
   "source": [
    "## 8. 结果抽样展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txts = sorted(RESULT_DIR.glob('*.txt'))[:5]\n",
    "for path in sample_txts:\n",
    "    print(path.name)\n",
    "    print(path.read_text().strip())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}